{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "from time import sleep\n",
    "\n",
    "NUM_COLUMNS = 7\n",
    "COLUMN_HEIGHT = 6\n",
    "FOUR = 4\n",
    "MINMAX_DEPTH = 2\n",
    "MONTECARLO_SAMPLES = 5 #number of times \"play out\" is performed at each call of the simulation step \n",
    "MONTECARLO_STEPS = 20 #number of times MCTS sequence (select+expand+simulate+backprop) is iterated. However MCTS is called once for each possible move in montecarlo only mode \n",
    "EVAL_MODE = 1 #0 for minmax + montecarlo, 1 for montecarlo only\n",
    "\n",
    "# Board can be initiatilized with `board = np.zeros((NUM_COLUMNS, COLUMN_HEIGHT), dtype=np.byte)`\n",
    "# Notez Bien: Connect 4 \"columns\" are actually NumPy \"rows\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_moves(board):\n",
    "    \"\"\"Returns columns where a disc may be played\"\"\"\n",
    "    return [n for n in range(NUM_COLUMNS) if board[n, COLUMN_HEIGHT - 1] == 0]\n",
    "\n",
    "\n",
    "def play(board, column, player):\n",
    "    \"\"\"Updates `board` as `player` drops a disc in `column`\"\"\"\n",
    "    (index,) = next((i for i, v in np.ndenumerate(board[column]) if v == 0))\n",
    "    board[column, index] = player\n",
    "\n",
    "\n",
    "def take_back(board, column):\n",
    "    \"\"\"Updates `board` removing top disc from `column`\"\"\"\n",
    "    (index,) = [i for i, v in np.ndenumerate(board[column]) if v != 0][-1]\n",
    "    board[column, index] = 0\n",
    "\n",
    "\n",
    "def four_in_a_row(board, player):\n",
    "    \"\"\"Checks if `player` has a 4-piece line\"\"\"\n",
    "    return (\n",
    "        any(\n",
    "            all(board[c, r] == player)\n",
    "            for c in range(NUM_COLUMNS)\n",
    "            for r in (list(range(n, n + FOUR)) for n in range(COLUMN_HEIGHT - FOUR + 1))\n",
    "        )\n",
    "        or any(\n",
    "            all(board[c, r] == player)\n",
    "            for r in range(COLUMN_HEIGHT)\n",
    "            for c in (list(range(n, n + FOUR)) for n in range(NUM_COLUMNS - FOUR + 1))\n",
    "        )\n",
    "        or any(\n",
    "            np.all(board[diag] == player)\n",
    "            for diag in (\n",
    "                (range(ro, ro + FOUR), range(co, co + FOUR))\n",
    "                for ro in range(0, NUM_COLUMNS - FOUR + 1)\n",
    "                for co in range(0, COLUMN_HEIGHT - FOUR + 1)\n",
    "            )\n",
    "        )\n",
    "        or any(\n",
    "            np.all(board[diag] == player)\n",
    "            for diag in (\n",
    "                (range(ro, ro + FOUR), range(co + FOUR - 1, co - 1, -1))\n",
    "                for ro in range(0, NUM_COLUMNS - FOUR + 1)\n",
    "                for co in range(0, COLUMN_HEIGHT - FOUR + 1)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winrate_to_score(winrate, player):\n",
    "    if player == 1:\n",
    "        return winrate*2 -1\n",
    "    else:\n",
    "        return (1-winrate)*2 -1\n",
    "\n",
    "\n",
    "def minmax(board, player, depth, a,b):\n",
    "    if(four_in_a_row(board,-player)):\n",
    "        #d=\"\"\n",
    "        #for i in range(depth):\n",
    "        #    d= d+\" > \"\n",
    "        #print(d+ f\"terminal score:  {-player} moving player: {player}\")\n",
    "        return (-1,-player, depth)\n",
    "    \n",
    "    if(depth>= MINMAX_DEPTH):\n",
    "        #score, _, __, ___ = mc_simulate(board,player)\n",
    "        #d=\"\"\n",
    "        #for i in range(depth):\n",
    "        #    d= d+\" > \"\n",
    "        \n",
    "        winrate = montecarlo_wrap(board, -player)\n",
    "        score = winrate_to_score(winrate,-player)\n",
    "        #print(d+ f\"montecarlo score:  {score} winrate: {winrate} moving player: {player}\")\n",
    "        #print(board)\n",
    "        \n",
    "        return (-1,score, depth)\n",
    "\n",
    "    evaluations = list()\n",
    "    #print(valid_moves(board))\n",
    "    cur_a = -math.inf\n",
    "    cur_b = math.inf\n",
    "    for m in valid_moves(board):\n",
    "        play(board, m, player)\n",
    "        val = minmax(board,-player, depth+1, cur_a, cur_b)\n",
    "        evaluations.append((m,val[1], val[2]))\n",
    "        take_back(board, m)\n",
    "        if alpha_beta_stop(a,b,player, val[1]):\n",
    "            #print(f\"stopped a = {a} b = {b} cur val = {val[1]}, moving player: {player}\")\n",
    "            #print(\"cut!\")\n",
    "            break\n",
    "        cur_a, cur_b=alpha_beta_update(cur_a,cur_b, player, val[1])\n",
    "    \n",
    "    #print(f\"depth: {depth} player: {player} ab: {a} {b} cur_ab: {cur_a} {cur_b} evals: {evaluations} \")\n",
    "    \n",
    "    #biased to pick solution with least depth\n",
    "    if player>0:\n",
    "        ch=max(evaluations, key = lambda k: (k[1]*100, -k[2]) )\n",
    "        #d=\"\"\n",
    "        #for i in range(depth):\n",
    "        #    d= d+\" > \"\n",
    "        #print(d+ f\"moves: {evaluations} chosen move: {ch[0]} score:  {ch} moving player: {player}\")\n",
    "        return ch\n",
    "    else:\n",
    "        ch=min(evaluations, key=lambda k: (k[1]*100, k[2]))\n",
    "        #d=\"\"\n",
    "        #for i in range(depth):\n",
    "        #    d= d+\" > \"\n",
    "        #print(d+ f\"moves: {evaluations} chosen move: {ch[0]} score:  {ch} moving player: {player}\")\n",
    "        return ch\n",
    "\n",
    "def alpha_beta_update(a,b, player, cur):\n",
    "    if player <0 and cur < b:\n",
    "        #print(\"update\")\n",
    "        return a, cur\n",
    "    elif player > 0 and cur> a:\n",
    "        #print(\"update\"); \n",
    "        return cur, b \n",
    "    return a,b\n",
    "\n",
    "def alpha_beta_stop(a, b, player, cur):\n",
    "    if player <0 and cur <= a:\n",
    "        return True\n",
    "    elif player > 0 and cur >= b:\n",
    "        return True \n",
    "    return False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montecarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, board, num, den, player, parent, move):\n",
    "        self.board = np.copy(board)\n",
    "        self.num = num #unutilized\n",
    "\n",
    "        self.move = move #needed just for debugging\n",
    "        self.winmin = 0\n",
    "        self.winmax = 0\n",
    " \n",
    "        self.den = den\n",
    "        self.player=player\n",
    "        self.parent=parent\n",
    "        self.children=list()\n",
    "        self.terminal = four_in_a_row(board, -player)\n",
    "        self.n_children = 0\n",
    "        self.terminated_childrend = 0\n",
    "    \n",
    "    def simulate(self):\n",
    "\n",
    "        if self.terminal:\n",
    "            #you represent a stronger simulation, give stronger feedback now because you're not going to be selected again\n",
    "            draws=0\n",
    "            if self.player==-1:\n",
    "                winmax = MONTECARLO_SAMPLES*NUM_COLUMNS\n",
    "                winmin = 0\n",
    "                draws = 0\n",
    "            elif self.player == 1:\n",
    "                winmax = 0\n",
    "                winmin = MONTECARLO_SAMPLES*NUM_COLUMNS\n",
    "                draws = 0\n",
    "\n",
    "        else:\n",
    "            _,draws,winmax,winmin = mc_simulate(self.board, self.player)\n",
    "        \n",
    "        #update current node statistics\n",
    "        self.winmin += winmin + 0.5* draws\n",
    "        self.winmax += winmax + 0.5* draws\n",
    "        \n",
    "        self.den += winmax+winmin+draws\n",
    "\n",
    "        #print(f\"winmax {winmax} winmin {winmin} draws {draws}\")\n",
    "        #backpropagate evaluation\n",
    "        if self.parent:\n",
    "            #self.parent.backprop(winmax,winmin, draws, MONTECARLO_SAMPLES)\n",
    "            self.parent.backprop(winmax+ 0.5* draws,winmin+ 0.5* draws, winmax+winmin+draws)\n",
    "            \n",
    "        \n",
    "\n",
    "    def backprop(self,winmax,winmin,den):\n",
    "        #print(\"bp\")\n",
    "        self.winmax+=winmax\n",
    "        self.winmin +=winmin\n",
    "    \n",
    "        self.den += den\n",
    "        if self.parent:\n",
    "            self.parent.backprop(winmax,winmin, den)\n",
    "    \n",
    "    def expand(self):\n",
    "        #print(\"expanding\")\n",
    "        #print(self.board)\n",
    "        \n",
    "        for m in valid_moves(self.board):\n",
    "            \n",
    "            play(self.board,m,self.player)\n",
    "            c = node(self.board,0,0,-self.player, self,m)\n",
    "            c.simulate()\n",
    "            self.children.append(c)\n",
    "            \n",
    "            take_back(self.board, m)\n",
    "            if(c.terminal):\n",
    "                #the current state gives the opponent a win in 1 move, let parent node know they should not reach it and that algorithm should not waste time here\n",
    "                #print(f\"TERMINAL: previous move: {self.move} by {-self.player} winrate min: {self.winrate(-1)} winrate max: {self.winrate(1)}\")\n",
    "                #print(self.board)\n",
    "                \n",
    "                if self.parent:\n",
    "                    #clear all your contribution so far\n",
    "                    self.parent.backprop(-self.winmax,-self.winmin,-self.den)\n",
    "                    #turn it into a complete win/defeat contribution\n",
    "                    if self.player == -1:\n",
    "                        self.parent.backprop(0, self.den, self.den)\n",
    "                    else:\n",
    "                        self.parent.backprop( self.den,0, self.den)\n",
    "\n",
    "                if self.player == -1:\n",
    "                    self.winmax = 0\n",
    "                    self.winmin = self.den\n",
    "                else:\n",
    "                    self.winmin = 0\n",
    "                    self.winmax = self.den\n",
    "                self.terminal = True\n",
    "                #print(f\"TERMINAL AFTER: previous move: {self.move} by {-self.player} winrate min: {self.winrate(-1)} winrate max: {self.winrate(1)}\")\n",
    "               \n",
    "                break\n",
    "                \n",
    "        #print(f\"winrate for this {self.winrate()}\")\n",
    "        return self.children.copy()\n",
    "    def winrate(self, player):\n",
    "        if player == 1:\n",
    "            return self.winmax/self.den\n",
    "        elif player == -1:\n",
    "            return self.winmin/self.den\n",
    "        return 0.0\n",
    "        #simplified UCT\n",
    "        #return self.num/self.den\n",
    "         \n",
    "\n",
    "def mc_select(node):\n",
    "    if node.terminal:\n",
    "        return node\n",
    "    if not node.children:\n",
    "        return node\n",
    "    if not list(filter(lambda c: c.terminal == False, node.children)):\n",
    "        return node\n",
    "    cur_best = max(filter(lambda c: c.terminal == False, node.children), key= lambda n: n.winrate(node.player))\n",
    "\n",
    "    return mc_select(cur_best)\n",
    "\n",
    "def mc_playout(board, player):\n",
    "    p = -player\n",
    "    while valid_moves(board):\n",
    "        p = -p\n",
    "        c = np.random.choice(valid_moves(board))\n",
    "        play(board, c, p)\n",
    "        if four_in_a_row(board, p):\n",
    "            return p\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def mc_simulate(board, player):\n",
    "    \n",
    "    cnt = Counter(mc_playout(np.copy(board), player) for _ in range(MONTECARLO_SAMPLES))\n",
    "    return (cnt[1] - cnt[-1]) / MONTECARLO_SAMPLES, cnt[0], cnt[1], cnt[-1]\n",
    "\n",
    "def montecarlo_wrap(board, player, prev_move = -1):\n",
    "    #define root node\n",
    "    root = node(board, 0,0, -player, None,prev_move) #-player because it's their turn to move \n",
    "    if(root.terminal):\n",
    "        return 1.0\n",
    "    root.expand()\n",
    "\n",
    "    #main loop\n",
    "    for i in range(MONTECARLO_STEPS):\n",
    "        #selection: get leaf by going through path with best winrates \n",
    "        next_node = mc_select(root)\n",
    "\n",
    "        if next_node.terminal:\n",
    "            break\n",
    "        \n",
    "\n",
    "        #expand the node (expands + simulation + backpropagation)\n",
    "        children = next_node.expand()\n",
    "\n",
    "    #if prev_move == 1:\n",
    "        #tree_print(root, 0)\n",
    "    #return winrate of root node\n",
    "    return root.winrate(player) \n",
    "\n",
    "def tree_print(node, depth):\n",
    "    d=\"\"\n",
    "    for i in range(depth):\n",
    "        d= d+\" > \"\n",
    "    print(d+f\"previous move: {node.move} by {-node.player} winrate min: {node.winrate(-1)} winrate max: {node.winrate(1)} terminal: {node.terminal}\")\n",
    "    for child in node.children:\n",
    "        tree_print(child, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montecarlo_only(board, player):\n",
    "    #montecarlo evaluation for each possible move, then choose best move\n",
    "    evaluations = list()\n",
    "    print(\"ai is thinking aloud...\")\n",
    "    for m in valid_moves(board):\n",
    "        play(board, m, player)\n",
    "        winrate = montecarlo_wrap(board, player, m)\n",
    "        evaluations.append((m,winrate))\n",
    "        take_back(board, m)\n",
    "        print(f\"{m} gives {winrate} winrate\")\n",
    "    \n",
    "    return max(evaluations, key = lambda k: k[1])\n",
    "        \n",
    "\n",
    "#returns: move, score. Score is in range (-1,1) if using minmax+montecarlo (EVAL_MODE = 0), a winrate in range (0,1) with montecarlo only \n",
    "def eval_board(board, player):\n",
    "    if four_in_a_row(board, 1):\n",
    "        # Alice won\n",
    "        return -1,1\n",
    "    elif four_in_a_row(board, -1):\n",
    "        # Bob won\n",
    "        return -1,1\n",
    "    else:\n",
    "        # Not terminal, let's simulate...\n",
    "        if EVAL_MODE ==0:\n",
    "            \n",
    "            eval= minmax(board, player,0, -math.inf, math.inf)\n",
    "            return eval[0], eval[1]\n",
    "        elif EVAL_MODE == 1:\n",
    "            eval = montecarlo_only(board, player)\n",
    "            return eval[0], eval[1]\n",
    "        else:\n",
    "            print(\"wrong evaluation mode selected, check the EVAL_MODE constant\")\n",
    "            return -1,0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example (used for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "board = board = np.zeros((NUM_COLUMNS, COLUMN_HEIGHT), dtype=np.byte)\n",
    "play(board, 3, 1)\n",
    "play(board, 0, -1)\n",
    "play(board, 4, 1)\n",
    "play(board, 0, -1)\n",
    "#play(board, 5, 1)\n",
    "#play(board, 2, -1)\n",
    "play(board, 0, -1)\n",
    "#play(board,2,-1)\n",
    "#board*=-1\n",
    "\n",
    "print(board)\n",
    "#eval_board(board, 1)\n",
    "#play(board, 0, 1)\n",
    "#print(board)\n",
    "#eval_board(board, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Human vs AI handler (run to play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.4850340136054422 winrate\n",
      "1 gives 0.46938775510204084 winrate\n",
      "2 gives 0.5346938775510204 winrate\n",
      "3 gives 0.6612244897959184 winrate\n",
      "4 gives 0.5795918367346938 winrate\n",
      "5 gives 0.5183673469387755 winrate\n",
      "6 gives 0.49183673469387756 winrate\n",
      "ai played 3\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 4\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.5591836734693878 winrate\n",
      "1 gives 0.5482993197278911 winrate\n",
      "2 gives 0.62 winrate\n",
      "3 gives 0.6054421768707483 winrate\n",
      "4 gives 0.6428571428571429 winrate\n",
      "5 gives 0.6 winrate\n",
      "6 gives 0.5359477124183006 winrate\n",
      "ai played 4\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [-1  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 3\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.5821192052980132 winrate\n",
      "1 gives 0.6 winrate\n",
      "2 gives 0.5210884353741496 winrate\n",
      "3 gives 0.6074829931972789 winrate\n",
      "4 gives 0.6108843537414966 winrate\n",
      "5 gives 0.5680272108843537 winrate\n",
      "6 gives 0.4775510204081633 winrate\n",
      "ai played 4\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 2\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.7515337423312883 winrate\n",
      "1 gives 0.6020408163265306 winrate\n",
      "2 gives 0.7335483870967742 winrate\n",
      "3 gives 0.64421768707483 winrate\n",
      "4 gives 0.7264516129032258 winrate\n",
      "5 gives 0.6591836734693878 winrate\n",
      "6 gives 0.6529801324503312 winrate\n",
      "ai played 0\n",
      "[[ 1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 1\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.6204081632653061 winrate\n",
      "1 gives 0.6835526315789474 winrate\n",
      "2 gives 0.6578231292517007 winrate\n",
      "3 gives 0.6768707482993197 winrate\n",
      "4 gives 0.7746987951807229 winrate\n",
      "5 gives 0.6635220125786163 winrate\n",
      "6 gives 0.628476821192053 winrate\n",
      "ai played 4\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  1  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 4\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.6358620689655172 winrate\n",
      "1 gives 0.6398648648648648 winrate\n",
      "2 gives 0.436986301369863 winrate\n",
      "3 gives 0.5312925170068027 winrate\n",
      "4 gives 0.41818181818181815 winrate\n",
      "5 gives 0.6 winrate\n",
      "6 gives 0.6083333333333333 winrate\n",
      "ai played 1\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1  0  0  0  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 2\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1  0  0  0  0]\n",
      " [-1 -1  0  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.4583850931677019 winrate\n",
      "1 gives 0.23431952662721894 winrate\n",
      "2 gives 0.885430463576159 winrate\n",
      "3 gives 0.7354838709677419 winrate\n",
      "4 gives 0.4129770992366412 winrate\n",
      "5 gives 0.45527950310559007 winrate\n",
      "6 gives 0.525974025974026 winrate\n",
      "ai played 2\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1  0  0  0  0]\n",
      " [-1 -1  1  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 1\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  0  0  0]\n",
      " [ 1 -1  0  0  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.7623287671232877 winrate\n",
      "1 gives 0.8503355704697987 winrate\n",
      "2 gives 0.9265822784810127 winrate\n",
      "3 gives 0.9648648648648649 winrate\n",
      "4 gives 0.7307692307692307 winrate\n",
      "5 gives 0.8013605442176871 winrate\n",
      "6 gives 0.8433121019108281 winrate\n",
      "ai played 3\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  0  0  0]\n",
      " [ 1 -1  1  0  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 3\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  0  0  0]\n",
      " [ 1 -1  1 -1  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.4950354609929078 winrate\n",
      "1 gives 0.7519685039370079 winrate\n",
      "2 gives 0.9335365853658537 winrate\n",
      "3 gives 0.7535483870967742 winrate\n",
      "4 gives 0.5653846153846154 winrate\n",
      "5 gives 0.6925675675675675 winrate\n",
      "6 gives 0.3957746478873239 winrate\n",
      "ai played 2\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  1  0  0]\n",
      " [ 1 -1  1 -1  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 5\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  1  0  0]\n",
      " [ 1 -1  1 -1  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.8952702702702703 winrate\n",
      "1 gives 0.8773049645390071 winrate\n",
      "2 gives 0.91 winrate\n",
      "3 gives 0.8703703703703703 winrate\n",
      "4 gives 0.7883561643835616 winrate\n",
      "5 gives 0.7574468085106383 winrate\n",
      "6 gives 0.8348684210526316 winrate\n",
      "ai played 2\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  1  1  0]\n",
      " [ 1 -1  1 -1  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 2, 3, 4, 5, 6]\n",
      "you chose 2\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1  0  0]\n",
      " [-1  1  1  1 -1  0]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 3, 4, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.9016260162601626 winrate\n",
      "1 gives 0.8639097744360902 winrate\n",
      "3 gives 0.89453125 winrate\n",
      "4 gives 0.9134328358208955 winrate\n",
      "5 gives 0.7146551724137931 winrate\n",
      "6 gives 0.8947368421052632 winrate\n",
      "ai played 4\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1  0  0]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 3, 5, 6]\n",
      "you chose 3\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  0  0  0]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  0]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 3, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.8541284403669724 winrate\n",
      "1 gives 0.9276785714285715 winrate\n",
      "3 gives 0.9132653061224489 winrate\n",
      "5 gives 0.820952380952381 winrate\n",
      "6 gives 0.8418803418803419 winrate\n",
      "ai played 1\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  1  0  0]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  0]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 3, 5, 6]\n",
      "you chose 1\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  1 -1  0]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  0]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 3, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.7580645161290323 winrate\n",
      "1 gives 0.79125 winrate\n",
      "3 gives 0.8797752808988764 winrate\n",
      "5 gives 0.6698795180722892 winrate\n",
      "6 gives 0.8046728971962617 winrate\n",
      "ai played 3\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  1 -1  0]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 5, 6]\n",
      "you chose 6\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  1 -1  0]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]]\n",
      "legal moves are [0, 1, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.8127450980392157 winrate\n",
      "1 gives 0.9255555555555556 winrate\n",
      "5 gives 0.7064516129032258 winrate\n",
      "6 gives 0.8917647058823529 winrate\n",
      "ai played 1\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1  0  0  0  0  0]]\n",
      "legal moves are [0, 5, 6]\n",
      "you chose 6\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  0  0  0  0]]\n",
      "legal moves are [0, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.8853658536585366 winrate\n",
      "5 gives 0.7606060606060606 winrate\n",
      "6 gives 0.9628205128205128 winrate\n",
      "ai played 6\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1  0  0  0]]\n",
      "legal moves are [0, 5, 6]\n",
      "you chose 6\n",
      "[[ 1  0  0  0  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1 -1  0  0]]\n",
      "legal moves are [0, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.9666666666666667 winrate\n",
      "5 gives 0.9257142857142857 winrate\n",
      "6 gives 0.961764705882353 winrate\n",
      "ai played 0\n",
      "[[ 1  1  0  0  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1 -1  0  0]]\n",
      "legal moves are [0, 5, 6]\n",
      "you chose 0\n",
      "[[ 1  1 -1  0  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1 -1  0  0]]\n",
      "legal moves are [0, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.9901234567901235 winrate\n",
      "5 gives 0.5586206896551724 winrate\n",
      "6 gives 0.9703703703703703 winrate\n",
      "ai played 0\n",
      "[[ 1  1 -1  1  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1 -1  0  0]]\n",
      "legal moves are [0, 5, 6]\n",
      "you chose 6\n",
      "[[ 1  1 -1  1  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1 -1 -1  0]]\n",
      "legal moves are [0, 5, 6]\n",
      "ai is thinking aloud...\n",
      "0 gives 0.9948717948717949 winrate\n",
      "5 gives 0.9698795180722891 winrate\n",
      "6 gives 0.9976190476190476 winrate\n",
      "ai played 6\n",
      "[[ 1  1 -1  1  0  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1 -1 -1  1]]\n",
      "legal moves are [0, 5]\n",
      "you chose 0\n",
      "[[ 1  1 -1  1 -1  0]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1 -1 -1  1]]\n",
      "legal moves are [0, 5]\n",
      "ai is thinking aloud...\n",
      "0 gives 1.0 winrate\n",
      "5 gives 0.9896103896103896 winrate\n",
      "ai played 0\n",
      "[[ 1  1 -1  1 -1  1]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1  0  0  0  0  0]\n",
      " [-1 -1  1 -1 -1  1]]\n",
      "legal moves are [5]\n",
      "you chose 5\n",
      "[[ 1  1 -1  1 -1  1]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1 -1  0  0  0  0]\n",
      " [-1 -1  1 -1 -1  1]]\n",
      "legal moves are [5]\n",
      "ai is thinking aloud...\n",
      "5 gives 1.0 winrate\n",
      "ai played 5\n",
      "[[ 1  1 -1  1 -1  1]\n",
      " [-1  1 -1  1 -1  1]\n",
      " [-1 -1  1  1  1 -1]\n",
      " [ 1 -1  1 -1 -1  1]\n",
      " [-1  1  1  1 -1  1]\n",
      " [-1 -1  1  0  0  0]\n",
      " [-1 -1  1 -1 -1  1]]\n",
      "ai won!!!\n"
     ]
    }
   ],
   "source": [
    "def match(board):\n",
    "    start= input(\"who will start? ('h' for human, 'a' for AI, default is human): \")\n",
    "    ai=-1\n",
    "    human = 1\n",
    "    if(start == 'a'):\n",
    "        \n",
    "        human = -1\n",
    "        ai = 1\n",
    "    curplayer = 1\n",
    "\n",
    "    while valid_moves(board):\n",
    "        print(board)\n",
    "        sleep(0.5)\n",
    "        \n",
    "        \n",
    "        print(f\"legal moves are {valid_moves(board)}\")\n",
    "        if curplayer == human:\n",
    "            \n",
    "            move = -1\n",
    "            \n",
    "            while not False:\n",
    "                move = int(input(\"type your move:\"))\n",
    "                if move not in valid_moves(board):\n",
    "                    print(\"illegal move!\")\n",
    "                else:\n",
    "                    print(f\"you chose {move}\")\n",
    "                    break\n",
    "            play(board, move, curplayer)\n",
    "            \n",
    "        elif curplayer == ai:\n",
    "            move = eval_board(board, curplayer)\n",
    "            print(f\"ai played {move[0]}\")\n",
    "            play(board,move[0], curplayer)\n",
    "            \n",
    "        \n",
    "        if four_in_a_row(board, human):\n",
    "            print(board)\n",
    "            print(\"you won!\")\n",
    "            break\n",
    "        elif four_in_a_row(board, ai):\n",
    "            print(board)\n",
    "            print(\"ai won!!!\")\n",
    "            break\n",
    "        \n",
    "        curplayer*=-1\n",
    "        \n",
    "\n",
    "board = board = np.zeros((NUM_COLUMNS, COLUMN_HEIGHT), dtype=np.byte)\n",
    "match(board)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
